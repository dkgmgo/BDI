{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Intelligence Assignment 2\n",
    "\n",
    "This is the code for the Assignment 2. Some parts taking too much execution time on my PC are commented, you should uncomment them if you want to see the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 : Data Preprocessing\n",
    "\n",
    "First we are going to create a map for the user indices and then we are going to build the matrices as specified, the matrices are 0 indexed so X[user_1, movie_1] = X[0, 0].\n",
    "We also wrote some tests to ensure we preprocessed the data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Users...\n",
      "Users Mapping Done\n"
     ]
    }
   ],
   "source": [
    "# Users Mapping\n",
    "\n",
    "user_ids = []\n",
    "print(\"Mapping Users...\")\n",
    "with open('./Project2-data/users.txt', 'r') as file:\n",
    "    user_ids = [int(line.strip()) for line in file]\n",
    "user_id_to_index = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "print(\"Users Mapping Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing file ./Project2-data/netflix_train.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6897746it [00:10, 678705.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete.\n",
      "Matrix X shape: (10000, 10000)\n",
      "Known ratings count: 6897746\n",
      "Preprocessing file ./Project2-data/netflix_test.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1719466it [00:02, 679243.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete.\n",
      "Matrix X shape: (10000, 10000)\n",
      "Known ratings count: 1719466\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_file(filename: str):\n",
    "    \"\"\"\n",
    "    Preprocesses a Netflix-style dataset file into sparse matrices for ratings and indicators.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the dataset file.\n",
    "\n",
    "    Returns:\n",
    "        csr_matrix: Sparse matrix (X) containing user ratings.\n",
    "        csr_matrix: Sparse matrix (IM) indicating known ratings (1) vs unknown ratings (0).\n",
    "    \"\"\"\n",
    "    print(f\"Preprocessing file {filename}...\")\n",
    "    num_users = len(user_id_to_index)\n",
    "    num_movies = 10000\n",
    "    \n",
    "    X = np.zeros((num_users, num_movies), dtype=np.int8) # rating matrix\n",
    "    IM = np.zeros((num_users, num_movies), dtype=np.int8) # indicator matrix\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            user_id, movie_idx, rating, _ = line.split()\n",
    "            user_idx, movie_idx, rating = user_id_to_index[int(user_id)], int(movie_idx), int(rating)\n",
    "            X[user_idx, movie_idx - 1] = rating # adjust movie index to 0-based\n",
    "            IM[user_idx, movie_idx - 1] = 1\n",
    "            \n",
    "    print(\"Data preprocessing complete.\")\n",
    "    print(f\"Matrix X shape: {X.shape}\")\n",
    "    print(f\"Known ratings count: {int(IM.sum())}\")\n",
    "    \n",
    "    return csr_matrix(X), csr_matrix(IM)\n",
    "\n",
    "X_train, IM_train = preprocess_file('./Project2-data/netflix_train.txt')\n",
    "X_test, IM_test = preprocess_file('./Project2-data/netflix_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "user_id, movie_idx, rating, _ = open('./Project2-data/netflix_train.txt', 'r').readline().split()\n",
    "assert X_train[user_id_to_index[int(user_id)], int(movie_idx) - 1] == int(rating)\n",
    "\n",
    "user_id, movie_idx, rating, _ = open('./Project2-data/netflix_test.txt', 'r').readline().split()\n",
    "assert X_test[user_id_to_index[int(user_id)], int(movie_idx) - 1] == int(rating)\n",
    "\n",
    "assert (X_train.data >= 1).all() and (X_train.data <= 5).all()\n",
    "\n",
    "assert (X_test.data >= 1).all() and (X_test.data <= 5).all()\n",
    "\n",
    "print(\"All tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 : Collaborative Filtering\n",
    "\n",
    "Here we are going to compute the similarities first, then implement the user-based collaborative filtering. After that we will check the RMSE and execution time for different values of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarity matrix...\n",
      "Similarity matrix computed.\n"
     ]
    }
   ],
   "source": [
    "# Similarity Matrix\n",
    "import numpy as np\n",
    "\n",
    "def compute_similarity_matrix(X):\n",
    "    \"\"\"\n",
    "    Computes the similarity matrix between users based on the cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        X (csr_matrix): Sparse matrix containing user ratings.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Similarity matrix between users.\n",
    "    \"\"\"\n",
    "    print(\"Computing similarity matrix...\")\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    norm_X = X / norms\n",
    "    S = norm_X @ norm_X.T\n",
    "    print(\"Similarity matrix computed.\")\n",
    "    \n",
    "    return S\n",
    "\n",
    "S_train = compute_similarity_matrix(X_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user-based collaborative filtering predictions...\n",
      "k_neighbors:  500\n",
      "Computing predictions...\n",
      "Computing RMSE...\n",
      "Prediction shape :  (10000, 10000)\n",
      "Final RMSE: 0.9791010971537276\n",
      "User-based collaborative filtering predictions computed.\n"
     ]
    }
   ],
   "source": [
    "# Collaborative Filtering\n",
    "import numpy as np\n",
    "\n",
    "def user_based_collaborative_filtering(X_train, IM_train, X_test, IM_test, S_train, k_neighbors=500):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train (np.ndarray): ratings matrix for training set\n",
    "        IM_train (np.ndarray): indicator matrix for training set\n",
    "        X_test (np.ndarray): ratings matrix for test set\n",
    "        IM_test (np.ndarray): indicator matrix for test set\n",
    "        S_train (np.ndarray): similarity matrix between users\n",
    "        k_neighbors (int, optional): Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        rmse (float): root mean squared error of the predictions\n",
    "        predictions (np.ndarray): predicted ratings for the test set\n",
    "    \"\"\"\n",
    "    print(\"k_neighbors: \", k_neighbors)\n",
    "    for i in range(X_train.shape[0]):\n",
    "        top_k_indices = list(np.argsort(S_train[i, :])[-k_neighbors-1:]) # actually top k+1 indices since the self similarity is 1\n",
    "        top_k_indices.pop() # remove self\n",
    "        mask = np.ones(X_train.shape[0], dtype=bool)\n",
    "        mask[top_k_indices] = False\n",
    "        S_train[i, mask] = 0\n",
    "    \n",
    "    print(\"Computing predictions...\") \n",
    "    weighted_sum = S_train @ X_train\n",
    "    sim_sum = S_train @ IM_train\n",
    "    sim_sum[sim_sum == 0] = 1 # avoid division by zero\n",
    "    predictions = weighted_sum / sim_sum\n",
    "    \n",
    "    print(\"Computing RMSE...\")\n",
    "    actual_ratings = X_test[IM_test > 0]\n",
    "    predicted_ratings = predictions[IM_test > 0]\n",
    "    rmse = np.sqrt(np.mean((actual_ratings - predicted_ratings) ** 2))\n",
    "\n",
    "    return rmse, predictions\n",
    "\n",
    "print(\"Computing user-based collaborative filtering predictions...\")\n",
    "rmse, predictions = user_based_collaborative_filtering(X_train.toarray(), IM_train.toarray(), X_test.toarray(), IM_test.toarray(), S_train.copy())\n",
    "print(\"Prediction shape : \", predictions.shape)\n",
    "print(f\"Final RMSE: {rmse}\")\n",
    "print(\"User-based collaborative filtering predictions computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_rmse_vs_k():\n",
    "    \"\"\"\n",
    "    Plots RMSE vs k for user-based collaborative filtering.\n",
    "    \"\"\"\n",
    "    k_values = [1, 10, 100, 500, 1000, 2000, 5000, 10000]\n",
    "    results = []\n",
    "    for k in k_values:\n",
    "        rmse, _ = user_based_collaborative_filtering(X_train.toarray(), IM_train.toarray(), X_test.toarray(), IM_test.toarray(), S_train.copy(), k_neighbors=k)\n",
    "        results.append(rmse)\n",
    "\n",
    "    # Plotting\n",
    "    plt.plot(k_values, results)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE vs k\")\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to plot RMSE vs k. around 10 minutes to run for all the values of k.\n",
    "# plot_rmse_vs_k() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 : Matrix Decomposition\n",
    "\n",
    "In this part we are going to implement a Adam optimizer for matrix decomposition. We will also to focus a bit on initialization and parameters selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def init_matrix(m, k, init_type):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        m (int): Number of rows.\n",
    "        k (int): Number of columns.\n",
    "        init_type (str): Type of initialization.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Initialized matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    def uniform(m, k):\n",
    "        return np.random.uniform(size=(m, k))\n",
    "    \n",
    "    def normal(m, k):\n",
    "        return np.random.normal(0, 1/k, size=(m, k))\n",
    "    \n",
    "    def ones(m, k):\n",
    "        return np.ones((m, k))\n",
    "    \n",
    "    def sparse(m, k):\n",
    "        num_elements_to_fill = m*k // 100\n",
    "    \n",
    "        matrix = np.zeros((m, k))\n",
    "\n",
    "        for _ in range(num_elements_to_fill):\n",
    "            i, j = np.random.randint(0, m), np.random.randint(0, k)\n",
    "            matrix[i, j] = np.random.randint(1, 6)\n",
    "        \n",
    "        return matrix\n",
    "    \n",
    "    matrix_init = {\n",
    "        'uniform': uniform,\n",
    "        'normal': normal,\n",
    "        'ones': ones,\n",
    "        'sparse': sparse\n",
    "    }\n",
    "    \n",
    "    return matrix_init[init_type](m, k)\n",
    "\n",
    "def adam_for_matrix_decomposition(X_train, IM_train, X_test, IM_test, k=50, alpha=1e-3, beta1=0.9, beta2=0.999, epsilon=1e-8, lambda_param=0.01, max_iter=1000, threshold=0.1, init_type='normal'):\n",
    "    \"\"\"\n",
    "        Adam optimizer for matrix decomposition.\n",
    "    \"\"\"\n",
    "    m, n = X_train.shape\n",
    "    U = init_matrix(m, k, init_type)\n",
    "    V = init_matrix(n, k, init_type)\n",
    "    \n",
    "    # Initialize Adam parameters\n",
    "    m_U = np.zeros_like(U)\n",
    "    v_U = np.zeros_like(U)\n",
    "    m_V = np.zeros_like(V)\n",
    "    v_V = np.zeros_like(V)\n",
    "    \n",
    "    X_pred = U @ V.T\n",
    "    \n",
    "    history = []\n",
    "    init_time = time.time()\n",
    "    for t in tqdm(range(1, max_iter + 1)):\n",
    "        error = IM_train * (X_pred - X_train)\n",
    "        grad_U = (error @ V) + 2 * lambda_param * U\n",
    "        grad_V = (error.T @ U) + 2 * lambda_param * V\n",
    "        \n",
    "        m_U = beta1 * m_U + (1 - beta1) * grad_U\n",
    "        v_U = beta2 * v_U + (1 - beta2) * (grad_U ** 2)\n",
    "        m_U_hat = m_U / (1 - beta1 ** t)\n",
    "        v_U_hat = v_U / (1 - beta2 ** t)\n",
    "        U -= alpha * m_U_hat / (np.sqrt(v_U_hat) + epsilon)\n",
    "        \n",
    "        m_V = beta1 * m_V + (1 - beta1) * grad_V\n",
    "        v_V = beta2 * v_V + (1 - beta2) * (grad_V ** 2)\n",
    "        m_V_hat = m_V / (1 - beta1 ** t)\n",
    "        v_V_hat = v_V / (1 - beta2 ** t)\n",
    "        V -= alpha * m_V_hat / (np.sqrt(v_V_hat) + epsilon)\n",
    "        \n",
    "        X_pred = U @ V.T\n",
    "        \n",
    "        target = lambda_param * (np.linalg.norm(U) ** 2 + np.linalg.norm(V) ** 2)\n",
    "        target += 0.5 * np.linalg.norm(IM_train * (X_train - X_pred)) ** 2\n",
    "        \n",
    "        rmse = np.sqrt(np.mean((X_test[IM_test > 0] - X_pred[IM_test > 0]) ** 2))\n",
    "        history.append((target, rmse, time.time() - init_time))\n",
    "        \n",
    "        if t % 50 == 0:\n",
    "            print(f\"Iteration {t}, target: {target}\", \"RMSE: \", rmse)\n",
    "        \n",
    "        if t > 1 and abs(history[-1][0] - history[-2][0]) < threshold:\n",
    "            print(f\"Converged after {t} iterations.\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Adam completed in {time.time() - init_time} seconds after {t} iterations\", \"Final RMSE: \", rmse)\n",
    "    \n",
    "    return U, V, history\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_target_rmse(k, lambda_param, init_type='normal', max_iter=1000):\n",
    "    \"\"\"\n",
    "    Plots target function and RMSE over iterations.\n",
    "    \"\"\"\n",
    "    _, _, history = adam_for_matrix_decomposition(X_train=X_train.toarray(), X_test=X_test.toarray(), IM_train=IM_train.toarray(), IM_test=IM_test.toarray(), k=k, lambda_param=lambda_param, init_type=init_type, max_iter=max_iter)\n",
    "    targets = [target for target, _, _ in history]\n",
    "    rmses = [rmse for _, rmse, _ in history]\n",
    "    iterations = range(len(history))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "    ax1.plot(iterations, targets, c='red')\n",
    "    ax1.set_ylabel('Target function')\n",
    "    ax2.plot(iterations, rmses, c='blue')\n",
    "    ax2.set_ylabel('RMSE')\n",
    "    fig.suptitle('Target function and RMSE over iterations') \n",
    "    plt.show()\n",
    "    \n",
    "    return history # return history for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target function and RMSE for k=50 and lambda=0.01\n",
    "# Uncomment to plot target function and RMSE over iterations. takes around 30 minutes to run.\n",
    "#history1 = plot_target_rmse(50, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different initializations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_final_rmse_vs_init_type():\n",
    "    \"\"\"\n",
    "    Plots RMSE vs iterations for matrix decomposition.\n",
    "    \"\"\"\n",
    "    init_types = ['uniform', 'normal', 'ones', 'sparse']\n",
    "    results = []\n",
    "    for init_type in init_types:\n",
    "        _, _, history = adam_for_matrix_decomposition(X_train=X_train.toarray(), X_test=X_test.toarray(), IM_train=IM_train.toarray(), IM_test=IM_test.toarray(), init_type=init_type, max_iter=100)\n",
    "        results.append(history[-1][1])\n",
    "\n",
    "    # Plotting\n",
    "    plt.bar(init_types, results, width=0.4)\n",
    "    plt.xlabel(\"Initialization Type\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE vs Initialization type (max_iter=100)\")\n",
    "    plt.show()\n",
    "    \n",
    "# Uncomment to plot RMSE vs initialization type for matrix decomposition. takes around 15 minutes to run.\n",
    "#plot_final_rmse_vs_init_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Values of K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_final_rmse_vs_k_matrix_decomposition():\n",
    "    k_values = [1, 10, 50, 100, 500, 1000, 2000]\n",
    "    results = []\n",
    "    for k in k_values:\n",
    "        _, _, history = adam_for_matrix_decomposition(X_train=X_train.toarray(), X_test=X_test.toarray(), IM_train=IM_train.toarray(), IM_test=IM_test.toarray(), k=k, max_iter=100)\n",
    "        results.append(history[-1][1])\n",
    "    \n",
    "    # Plotting\n",
    "    plt.bar([str(el) for el in k_values], results, width=0.4)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE vs k (max_iter=100; init_type=normal)\")\n",
    "    plt.show()\n",
    "    \n",
    "    return results # return results for testing\n",
    "    \n",
    "# Uncomment to plot RMSE vs k for matrix decomposition. Takes around 70 minutes to run.\n",
    "#results = plot_final_rmse_vs_k_matrix_decomposition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Values of Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_final_rmse_vs_lambda_matrix_decomposition():\n",
    "    lambda_values = [0.0001, 0.001, 0.01, 0.1]\n",
    "    results = []\n",
    "    for lambda_param in lambda_values:\n",
    "        _, _, history = adam_for_matrix_decomposition(X_train=X_train.toarray(), X_test=X_test.toarray(), IM_train=IM_train.toarray(), IM_test=IM_test.toarray(), lambda_param=lambda_param, max_iter=100)\n",
    "        results.append(history[-1][1])\n",
    "    \n",
    "    # Plotting\n",
    "    plt.bar([str(el) for el in lambda_values], results, width=0.4)\n",
    "    plt.xlabel(\"Lambda\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE vs Lambda (max_iter=100, init_type=normal)\")\n",
    "    plt.show()\n",
    "    \n",
    "    return results # return results for testing\n",
    "    \n",
    "# Uncomment to plot RMSE vs lambda for matrix decomposition. Takes around 17 minutes to run.\n",
    "#results = plot_final_rmse_vs_lambda_matrix_decomposition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After parameters selection, we can use the best parameters to compute the final RMSE\n",
    "# Uncomment to compute final RMSE with the best parameters. Takes around 30 minutes to run.\n",
    "# history_n = plot_target_rmse(k=500, lambda_param=0.01, init_type='normal', max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "Here we want to compare the performances of the 2 aproaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time vs RMSE\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_execution_time_vs_rmse():\n",
    "    \"\"\"\n",
    "    Plots execution time vs RMSE for user-based collaborative filtering and matrix decomposition.\n",
    "    \"\"\"\n",
    "    # User-based collaborative filtering\n",
    "    k_values = [1, 10, 100, 500, 1000]\n",
    "    results1 = []\n",
    "    for k in k_values:\n",
    "        t = time.time()\n",
    "        rmse, _ = user_based_collaborative_filtering(X_train.toarray(), IM_train.toarray(), X_test.toarray(), IM_test.toarray(), S_train.copy(), k_neighbors=k)\n",
    "        results1.append((rmse, time.time() - t))\n",
    "    \n",
    "    # Matrix decomposition\n",
    "    _, _, history = adam_for_matrix_decomposition(X_train=X_train.toarray(), X_test=X_test.toarray(), IM_train=IM_train.toarray(), IM_test=IM_test.toarray(), max_iter=100, k=500)\n",
    "    results2 = [(history[i][1], history[i][2]) for i in range(0, len(history), 5)]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(*zip(*results1), label=\"CF\")\n",
    "    plt.plot(*zip(*results2), label=\"MD\")\n",
    "    plt.ylabel(\"Execution Time (s)\")\n",
    "    plt.xlabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return results1, results2 # return results for testing\n",
    "\n",
    "# Uncomment to plot execution time vs RMSE. Takes around 35 minutes to run.\n",
    "#results1, results2 = plot_execution_time_vs_rmse()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
